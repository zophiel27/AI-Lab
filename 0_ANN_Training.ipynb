{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3tlNWdFa_2i",
        "outputId": "c30db446-cea0-4f70-b3f6-09105a236d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Weights: [0.2 0.1] and bias: [-0.2]\n",
            "Output: \n",
            "Predicted: 0 Desired [0]\n",
            "Predicted: 0 Desired [0]\n",
            "Predicted: 0 Desired [0]\n",
            "Predicted: 1 Desired [1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Define the input data for the AND gate\n",
        "input_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "# Define the target output for the AND gate\n",
        "target_output = np.array([[0], [0], [0], [1]])\n",
        "# Define the learning rate and the number of iterations\n",
        "learning_rate = 0.1\n",
        "num_iterations = 10\n",
        "\n",
        "# Define the activation function (step function)\n",
        "def activation_function(x):\n",
        "  return 1 if x >= 0 else 0\n",
        "\n",
        "# Initialize the weights and the bias\n",
        "weights = np.array([0.0, 0.0])\n",
        "bias = 0.0\n",
        "\n",
        "# Train the perceptron\n",
        "for i in range(num_iterations):\n",
        "  #print(\"\\nIteration \", i)\n",
        "  for j in range(len(input_data)):\n",
        "    x = input_data[j]\n",
        "    y = target_output[j]\n",
        "    # Calculate the weighted sum of the inputs and the bias\n",
        "    z = np.dot(x, weights)+bias\n",
        "    #print(\"Z: \", z, end = \" \")\n",
        "    # Calculate the predicted output using the activation function\n",
        "    _y = activation_function(z)\n",
        "    #print(\"\\nPredicted Output: \", _y)\n",
        "    # Calculate the error\n",
        "    error = y - _y\n",
        "    # Update the weights and the bias\n",
        "    weights = weights + learning_rate*error*x\n",
        "    bias = bias + learning_rate*error\n",
        "    #print(\"Updated weights:\", weights, \"Bias:\", bias)\n",
        "\n",
        "# Print learned weights\n",
        "print(\"Learned Weights:\", weights, \"and bias:\", bias)\n",
        "# Test the perceptron\n",
        "print(\"Output: \")\n",
        "test_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "for j in range(len(test_inputs)):\n",
        "  x = test_inputs[j]\n",
        "  y = target_output[j]\n",
        "  z = np.dot(x, weights)+bias\n",
        "  _y = activation_function(z)\n",
        "  print(\"Predicted:\", _y, \"Desired\", y)\n"
      ]
    }
  ]
}